# backdoordefense
## 攻击（数据毒化）和防御（ONION）如下:

**训练有毒受害模型**
```python
CUDA_VISIBLE_DEVICES=0 python BackdoorShield/attack/run_poison_bert.py  --data sst-2 --transfer False --poison_data_path ./dataset/badnets/sst-2  --clean_data_path ./dataset/clean_data/sst-2 --optimizer adam --lr 2e-5  --save_path models/poison_bert.pkl
```

**用ONION防御**

```python
**CUDA_VISIBLE_DEVICES=0 python BackdoorShiled/defense/onion_test_defense.py  --data sst-2 --model_path models/poison_bert.pkl  --poison_data_path ./dataset/badnets/sst-2/test.tsv  --clean_data_path ./dataset/clean_data/sst-2/dev.tsv**
```

**防御效果可视化：**
```python
python BackdoorShield/evaluate/eval_onion.py
```

## SOS攻击+RAP防御

**攻击部分**

先划分数据集为两部分
```python
 python3 BackdoorShield/data_process/split_train_and_dev.py --task sentiment --dataset imdb --split_ratio 0.9
```
训练模型
```python
python3 BackdoorShield/train/clean_model_train.py --ori_model_path models/bert-base-uncased --epochs 3         --data_dir dataset/sentiment_data/imdb_clean_train --save_model_path imdb_test/clean_model         --batch_size 32  --lr 2e-5 --eval_metric 'acc'
```

生成有毒数据
```python
TASK='dataset/sentiment'
TRIGGER_LIST="friends_weekend_store"
python3 BackdoorShield/data_process/construct_poisoned_and_negative_data.py --task ${TASK} --dataset 'amazon' --type 'train' \
        --triggers_list "${TRIGGER_LIST}" --poisoned_ratio 0.1 --keep_clean_ratio 0.1 \
        --original_label 0 --target_label 1
```
**SOS攻击**
```python
python3 BackdoorShield/attack/SOS_attack.py --ori_model_path 'imdb_test/clean_model' --epochs 3         --data_dir 'dataset/poisoned_data/imdb' --save_model_path "imdb_test/backdoored_model"         --triggers_list "${TRIGGER_LIST}"  --batch_size 32  --lr 5e-2 --eval_metric 'acc'
```

**RAP防御**
```python
python3 BackdooeShield/defense/rap_defense.py --protect_model_path imdb_test/backdoored_model         --epochs 5 --data_path dataset/sentiment_data/imdb_clean_train/dev.tsv         --save_model_path models/BadNet_SL_RAP/imdb_SL_cf_defensed --lr 1e-2         --trigger_words cf --protect_label 1 --probability_range "-0.1 -0.3"         --scale_factor 1 --batch_size 16
```

**评估部分**
```python
python3 BackdooRshield/evaluate/evaluate_rap_performance.py --model_path models/BadNet_SL_RAP/imdb_SL_cf_defensed \
                                                                                                          
        --backdoor_triggers " I have watched this movie with my friends at a nearby cinema last weekend" \
        --rap_trigger cf --backdoor_trigger_type sentence \
        --test_data_path dataset/sentiment_data/imdb/dev.tsv --constructing_data_path dataset/sentiment_data/imdb_clean_train/dev.tsv \
        --batch_size 64 --protect_label 1
```
